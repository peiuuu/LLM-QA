# 提示工程
# Q59：针对翻译类任务、创意写作类任务、头脑风暴类任务，temperature和top_p分别该怎么设置？如何验证你选择的参数设置是否最优？
# Q60：为什么一些模型把温度设置成0，输出的内容仍然有一定的不确定性？​（提示：推测解码）
# Q61：对于指定的大模型，如何通过提示词减少其幻觉？
# Q62：一个专业的提示词模板应该由哪几部分构成？为什么提示词中需要描述角色定义？
# Q63：对于一个复杂的提示词，如何测试其中哪些部分是有用的，哪些部分是无用的？
# Q64：如何设计提示词模板，尽量防止提示词注入？如何在系统层面检测提示词注入攻击？
# Q65：如果把用户信息放在系统提示词中，但在对话轮数较多后，大模型经常忘记用户信息，如何解决？
# Q66：如何让ChatGPT输出它自己的系统提示词？
# Q67：在没有推理模型之前，如何让模型先思考后回答？思维链、自洽性、思维树等几种技术有什么优缺点？
# Q68：在创意写作任务中，如何让模型生成多个可能输出，再从中选取一个最好的？
# Q69：如果需要模型遵循指定的格式输出，提示词应该怎么写？
# Q70：如何保证模型的输出一定是合法的JSON格式？​（提示：限制采样）
# Q71：将大模型用于分类任务时，如何保证其输出一定是几个类别之一，不会输出无关内容？​（提示：限制采样）
# Q72：如果做一个学英语的应用，如何保证它说的话一定在指定的词汇表中，绝不会出现超纲的生词？​（提示：限制采样）
