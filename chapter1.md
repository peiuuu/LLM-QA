# Q1：Transformer中的编码器和解码器有什么区别，只有编码器或者只有解码器的模型是否有用？
编码器负责表示输入序列，解码器负责生成输出序列。只有编码器或者只有解码器的模型有用，例如：BERT（只有编码器）、GPT（只有解码器）。
> Transformer中的编码器块由两部分组成：自注意力和前馈神经网络。与编码器相比，解码器多了一个注意力层，用于关注编码器的输出（以便找到输入中相关的部分）。
# Q2：GPT跟原始Transformer论文的模型架构有什么区别？
GPT(Generative Pre-trained Transformer)只有解码器(Decoder)，原始Transformer论文（Attention Is All You Need）的模型架构是编码器-解码器(Encoder-Decoder)。
> 原始的Transformer模型是一个编码器-解码器架构，虽然非常适合翻译任务，但难以用于其他任务，比如文本分类。
# Q3：仅编码器（BERT类）​、仅解码器（GPT类）和完整编码器-解码器架构各有什么优缺点？
* 仅编码器：通过双向上下文深度理解文本。
  * 优点：①深度上下文理解；②高效的特征提取；③模型相对较小。
  * 缺点：①不擅长生成任务；②任务形式受限。
* 仅解码器：通过单向（自回归）上下文生成文本。
  * 优点：①强大的生成能力；②任务通用性强；③零样本/少样本能力。
  * 缺点：①上下文理解的局限性；②计算成本高。
* 完整编码器-解码器：也称为序列到序列（Sequence-to-Sequence）架构。
  * 优点：①结合两者优势；②性能稳定；③转为序列转换设计。
  * 缺点：①通用性不如纯解码器。
# Q4：为什么说Transformer的自注意力机制相对于早期RNN中的注意力机制是一个显著的进步？
Transformer自注意力机制解决了RNN注意力机制在以下三个痛点上的核心局限：处理长距离依赖、并行计算能力、上下文表示丰富度。
> 注意力允许模型关注输入序列中彼此相关（相互“注意”）的部分，并放大它们的信号。注意力机制通过选择性地聚焦于句子中最关键的词，来突出其重要性。注意力机制使模型能够“注意”序列中彼此相关程度更高或更低的部分。Transformer完全基于注意力机制。与RNN相比，Transformer支持并行训练，这大大加快了训练速度。
# Q5：大模型为什么有最长上下文长度的概念？为什么它是指输入和输出的总长度？
1. 大模型的最长上下文长度。因为注意力机制的计算成本（时间和算力）和内存占用会随着长度二次方增长，硬件扛不住。
   >自注意力机制的核心思想是，在处理一个词（Token）时，它需要计算这个词与上下文中所有其他词的关联程度。如果你的上下文有 n
      个词，那么对于每个词，都要进行 n 次计算，总的计算复杂度大约是 n 的二次方，即 O(n²)。
2. 最长上下文长度指输入和输出的总长度。因为模型是“自回归”的，它每生成一个新词，都会把这个词加入到上下文中，作为下一次预测的依据。整个对话历史是一个不可分割的整体。
# Q6：大模型的首字延迟、输入吞吐量、输出吞吐量分别是如何计算的？不同应用场景对首字延迟、输入吞吐量和输出吞吐量的需求分别是什么？
* 首字延迟（Time To First Token,TTFT），指从用户发送请求（Prompt）到接收到模型生成的第一个文本片段（Token）所花费的时间。这个指标直接影响用户感受到的“反应速度”。
  * 首字延迟 = 接收到第一个Token的时间点 - 发送请求的时间点
* 输入吞吐量(Input Throughput)：指模型服务处理输入文本的速率，通常衡量模型在开始生成回复之前“阅读”和“理解”提示（Prompt）的速度。这个指标对于处理长文本输入（Large
     Context）的场景尤其重要。
  * 输入吞吐量 (Tokens/秒) = 输入Token的总数 / 输入处理总时长
* 输出吞吐量(Output Throughput / Generation Throughput)：指模型在生成第一个Token之后，持续生成后续内容的速度。通常用“每秒生成Token数”（Tokens per Second, TPS）来衡量。
  * 输出吞吐量 (Tokens/秒) = (生成的总Token数 - 1) / (接收到最后一个Token的时间点 - 接收到第一个Token的时间点)
# Q7：预训练和微调的两步范式为什么如此重要？基础模型通过预训练获得了哪些核心能力？微调在引导模型遵循指令、回答问题和对齐人类价值观方面起到什么作用？
1. 预训练使模型能够学习语法、上下文和语言模式。这个宽泛的训练阶段不是针对特定任务或应用的，而仅仅用于预测下一个词。这些模型通常不会遵循指令。
2. 微调也称后训练。微调使用先前训练好的模型，并在更具体的任务上进行进一步的训练。微调可以进一步使模型与用户偏好对齐。
# Q8：Llama-38B的综合能力比Llama-170B的能力还强，是如何做到的？
模型的能力不再仅仅由参数量（大小）决定，训练数据的质量、训练方法和模型架构的优化变得越来越重要。


* [Attention is All You Need](https://arxiv.org/pdf/1706.03762)
* [Generative Pre-trained Transformer](https://arxiv.org/pdf/2305.10435)
